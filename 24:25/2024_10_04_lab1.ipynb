{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>SVD decomposition with SciPy</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the required modules\n",
    "import scipy.linalg as la\n",
    "import numpy as np\n",
    "\n",
    "#Generate a 5x4 matrix\n",
    "np.random.seed(0) #Generate the same random numbers each time\n",
    "A = np.random.rand(5,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Input: a matrix $A$ of size $m \\times n$. <br>\n",
    "Oputput: U of size $m \\times m$, S of size $m \\times n$ and V of size $n \\times n$ <br>\n",
    "or, more precisely,<br>\n",
    "Ïƒ of size q<br>\n",
    "where q = min(m,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U shape (5, 5)\n",
      "s shape (4,)\n",
      "VT shape (4, 4)\n"
     ]
    }
   ],
   "source": [
    "U, s, VT = np.linalg.svd(A)\n",
    "print(\"U shape\", U.shape)\n",
    "print(\"s shape\", s.shape)\n",
    "print(\"VT shape\", VT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.64618677, 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.83351254, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.70753001, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.29842614],\n",
       "       [0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build the matrix S\n",
    "S = np.zeros(A.shape)\n",
    "for i in range(len(s)):\n",
    "    S[i,i] = s[i]\n",
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.64618677, 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.83351254, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.70753001, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.29842614],\n",
       "       [0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = la.diagsvd(s, A.shape[0], A.shape[1])\n",
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "err: 4.2743316456409587e-16\n"
     ]
    }
   ],
   "source": [
    "#Reconstruct the matrix A\n",
    "A_svd = np.matmul(U, np.matmul(S, VT))\n",
    "#Equivalently: A_svd = U @ S @ VT\n",
    "print(f\"err: {(la.norm(A-A_svd)/la.norm(A))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>A note on vectorization</h3>\n",
    "Vectorization refers to the practice of replacing explicit loops with high-level mathematical operations that act on entire arrays of matrices at once. This leads to much better performance because it replaces slow Python loops with fast, optimized C and Fortran operations.<br>\n",
    "Indeed, we could be inclined to reconstruct A_k with a for loop and the explicit formula\n",
    "\n",
    "$$\n",
    "A_k = \\sum_{i=1}^{k} \\sigma_{k} u_{k} v_{k}^{T}\n",
    "$$\n",
    "\n",
    "Let's measure the time taken for this operation for a matrix A that is a bit larger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for reconstruction using for loop: 0.107924 seconds\n",
      "Time for vectorized reconstruction: 0.000752 seconds\n",
      "Vectorized is 143.5 times faster than the loop\n",
      "Max difference between the two reconstructions: 8.881784e-16\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "A = np.random.rand(500, 400)\n",
    "U, s, VT = la.svd(A, full_matrices=False)\n",
    "S = np.diag(s)\n",
    "\n",
    "#Time the reconstruction with a for loop\n",
    "start_time = time.time()\n",
    "A_reconstructed_loop = np.zeros_like(A) #Initialize a matrix of zeros\n",
    "for i in range(len(s)):\n",
    "    A_reconstructed_loop += s[i] * np.outer(U[:,i], VT[i,:])\n",
    "loop_time = time.time() - start_time\n",
    "\n",
    "#Time the reconstruction using matrix multiplication\n",
    "start_time = time.time()\n",
    "#Here we are using broadcasting to avoid the creation of a diagonal matrix\n",
    "A_reconstructed_vectorized = (U * s) @ VT\n",
    "vectorized_time = time.time() - start_time\n",
    "\n",
    "#We compare the results\n",
    "print(f\"Time for reconstruction using for loop: {loop_time:.6f} seconds\")\n",
    "print(f\"Time for vectorized reconstruction: {vectorized_time:.6f} seconds\")\n",
    "print(f\"Vectorized is {loop_time/vectorized_time:.1f} times faster than the loop\")\n",
    "\n",
    "difference = np.abs(A_reconstructed_loop - A_reconstructed_vectorized).max()\n",
    "print(f\"Max difference between the two reconstructions: {difference:.6e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
